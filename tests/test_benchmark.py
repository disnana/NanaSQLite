"""
NanaSQLite Performance Benchmarks

pytest-benchmarkã‚’ä½¿ç”¨ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬
"""

import os
import tempfile
import pytest

# pytest-benchmarkãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
pytest_benchmark_available = True
try:
    import pytest_benchmark
except ImportError:
    pytest_benchmark_available = False


# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£
@pytest.fixture
def db_path():
    with tempfile.TemporaryDirectory() as tmpdir:
        yield os.path.join(tmpdir, "bench.db")


@pytest.fixture
def db(db_path):
    from nanasqlite import NanaSQLite
    database = NanaSQLite(db_path)
    yield database
    database.close()


@pytest.fixture
def db_with_data(db_path):
    """1000ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ãŸDB"""
    from nanasqlite import NanaSQLite
    database = NanaSQLite(db_path)
    for i in range(1000):
        database[f"key_{i}"] = {"index": i, "data": "x" * 100}
    yield database
    database.close()


# ==================== Write Benchmarks ====================

@pytest.mark.skipif(not pytest_benchmark_available, reason="pytest-benchmark not installed")
class TestWriteBenchmarks:
    """æ›¸ãè¾¼ã¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    
    def test_single_write(self, benchmark, db):
        """å˜ä¸€æ›¸ãè¾¼ã¿"""
        counter = [0]
        def write_single():
            db[f"key_{counter[0]}"] = {"data": "value", "number": counter[0]}
            counter[0] += 1
        
        benchmark(write_single)
    
    def test_nested_write(self, benchmark, db):
        """ãƒã‚¹ãƒˆã—ãŸãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿"""
        counter = [0]
        nested_data = {
            "level1": {
                "level2": {
                    "level3": {
                        "data": [1, 2, 3, {"nested": True}]
                    }
                }
            }
        }
        def write_nested():
            db[f"nested_{counter[0]}"] = nested_data
            counter[0] += 1
        
        benchmark(write_nested)
    
    def test_batch_write_100(self, benchmark, db_path):
        """ãƒãƒƒãƒæ›¸ãè¾¼ã¿ï¼ˆ100ä»¶ï¼‰"""
        from nanasqlite import NanaSQLite
        
        def batch_write():
            database = NanaSQLite(db_path)
            data = {f"batch_{i}": {"index": i} for i in range(100)}
            database.batch_update(data)
            database.close()
        
        benchmark(batch_write)


# ==================== Read Benchmarks ====================

@pytest.mark.skipif(not pytest_benchmark_available, reason="pytest-benchmark not installed")
class TestReadBenchmarks:
    """èª­ã¿è¾¼ã¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    
    def test_single_read_cached(self, benchmark, db_with_data):
        """å˜ä¸€èª­ã¿è¾¼ã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ï¼‰"""
        # ã¾ãšã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«å…¥ã‚Œã‚‹
        _ = db_with_data["key_500"]
        
        def read_cached():
            return db_with_data["key_500"]
        
        benchmark(read_cached)
    
    def test_single_read_uncached(self, benchmark, db_path):
        """å˜ä¸€èª­ã¿è¾¼ã¿ï¼ˆæœªã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
        from nanasqlite import NanaSQLite
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        db = NanaSQLite(db_path)
        db["target"] = {"data": "value"}
        db.close()
        
        def read_uncached():
            database = NanaSQLite(db_path, bulk_load=False)
            result = database["target"]
            database.close()
            return result
        
        benchmark(read_uncached)
    
    def test_bulk_load_1000(self, benchmark, db_path):
        """ä¸€æ‹¬ãƒ­ãƒ¼ãƒ‰ï¼ˆ1000ä»¶ï¼‰"""
        from nanasqlite import NanaSQLite
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        db = NanaSQLite(db_path)
        db.batch_update({f"key_{i}": {"index": i} for i in range(1000)})
        db.close()
        
        def bulk_load():
            database = NanaSQLite(db_path, bulk_load=True)
            database.close()
        
        benchmark(bulk_load)


# ==================== Dict Operations Benchmarks ====================

@pytest.mark.skipif(not pytest_benchmark_available, reason="pytest-benchmark not installed")
class TestDictOperationsBenchmarks:
    """dictæ“ä½œã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    
    def test_keys_1000(self, benchmark, db_with_data):
        """keys()å–å¾—ï¼ˆ1000ä»¶ï¼‰"""
        benchmark(db_with_data.keys)
    
    def test_contains_check(self, benchmark, db_with_data):
        """å­˜åœ¨ç¢ºèªï¼ˆinæ¼”ç®—å­ï¼‰"""
        def check_contains():
            return "key_500" in db_with_data
        
        benchmark(check_contains)
    
    def test_len(self, benchmark, db_with_data):
        """len()å–å¾—"""
        benchmark(len, db_with_data)
    
    def test_to_dict_1000(self, benchmark, db_with_data):
        """to_dict()å¤‰æ›ï¼ˆ1000ä»¶ï¼‰"""
        benchmark(db_with_data.to_dict)


# ==================== Summary Test ====================

def test_benchmark_summary(db_path, capsys):
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼ï¼ˆpytest-benchmarkç„¡ã—ã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰"""
    import time
    from nanasqlite import NanaSQLite
    
    results = {}
    
    # æ›¸ãè¾¼ã¿ãƒ†ã‚¹ãƒˆ
    db = NanaSQLite(db_path)
    start = time.perf_counter()
    for i in range(100):
        db[f"key_{i}"] = {"data": i}
    results["write_100"] = (time.perf_counter() - start) * 1000
    
    # èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ï¼‰
    start = time.perf_counter()
    for i in range(100):
        _ = db[f"key_{i}"]
    results["read_100_cached"] = (time.perf_counter() - start) * 1000
    
    db.close()
    
    # ä¸€æ‹¬ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
    start = time.perf_counter()
    db2 = NanaSQLite(db_path, bulk_load=True)
    results["bulk_load_100"] = (time.perf_counter() - start) * 1000
    db2.close()
    
    # çµæœè¡¨ç¤º
    print("\n" + "=" * 50)
    print("ğŸ“Š NanaSQLite Benchmark Summary")
    print("=" * 50)
    for name, ms in results.items():
        print(f"  {name}: {ms:.2f}ms")
    print("=" * 50)
