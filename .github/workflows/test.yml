name: NanaSQLite Tests

on:
  push:
    branches-ignore:
      - main
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - '.github/workflows/test.yml'
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - '.github/workflows/test.yml'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    runs-on: ${{ matrix.os }}
    timeout-minutes: 10
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.11", "3.13"]
        exclude:
          # Windows: only 3.13
          - os: windows-latest
            python-version: "3.11"

    steps:
    - uses: actions/checkout@v4
    
    - name: Install uv
      uses: astral-sh/setup-uv@v7
      with:
        enable-cache: true
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
    
    # Windows最適化: TEMPをD:ドライブに
    - name: Setup Windows temp directory
      if: runner.os == 'Windows'
      shell: powershell
      run: New-Item -ItemType Directory -Force -Path D:\temp

    - name: Install dependencies
      run: |
        uv pip install --system pytest pytest-benchmark pytest-asyncio pytest-xdist apsw pydantic
        uv pip install --system -e .
    
    # Windows: TEMP最適化 + 並列数固定
    - name: Run tests (Windows)
      if: runner.os == 'Windows'
      env:
        TEMP: 'D:\temp'
        TMP: 'D:\temp'
      run: |
        pytest tests/ -v --tb=short --junitxml=test-results.xml -n 4 --ignore=tests/test_benchmark.py --ignore=tests/test_async_benchmark.py

    # Linux/macOS: 変更なし
    - name: Run tests (Linux/macOS)
      if: runner.os != 'Windows'
      run: |
        pytest tests/ -v --tb=short --junitxml=test-results.xml -n auto --ignore=tests/test_benchmark.py --ignore=tests/test_async_benchmark.py
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
        path: test-results.xml
        retention-days: 7

  test-summary:
    needs: [test]
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: always()
    steps:
    - name: Download all test results
      uses: actions/download-artifact@v7
      with:
        pattern: test-results-*
        path: test-results
    
    - name: Test Summary
      run: |
        echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| OS | Python | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|---|---|---|" >> $GITHUB_STEP_SUMMARY
        for dir in test-results/*/; do
          name=$(basename "$dir")
          os=$(echo "$name" | sed 's/test-results-\(.*\)-py.*/\1/')
          py=$(echo "$name" | sed 's/.*-py\(.*\)/\1/')
          if [ -f "$dir/test-results.xml" ]; then
            errors=$(grep -o 'errors="[0-9]*"' "$dir/test-results.xml" | head -1 | grep -o '[0-9]*')
            failures=$(grep -o 'failures="[0-9]*"' "$dir/test-results.xml" | head -1 | grep -o '[0-9]*')
            if [ "$errors" = "0" ] && [ "$failures" = "0" ]; then
              echo "| $os | $py | ✅ Passed |" >> $GITHUB_STEP_SUMMARY
            else
              echo "| $os | $py | ❌ Failed |" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "| $os | $py | ⚠️ No results |" >> $GITHUB_STEP_SUMMARY
          fi
        done
